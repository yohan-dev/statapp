{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ya/miniconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3049: DtypeWarning: Columns (10,15,17,23,24,29,30,37) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "photos = pd.read_csv('photos.csv',encoding='latin-1')\n",
    "depeches = pd.read_csv('depeches.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "photos.dropna(subset=['event'], inplace= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(245475, 45)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "photos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depeches.event.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19975, 3)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depeches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(245475, 45)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print(photos.shape)\n",
    "photos.event.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mettre en liste la colonne event. des deux bases "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0 \n",
    "for k in photos.event:    \n",
    "    if k in depeches.event: \n",
    "        c+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13335\n"
     ]
    }
   ],
   "source": [
    "liste_ev_unique_depeches = []\n",
    "for ev in depeches.event:\n",
    "    for _ev in ev[1:-1].replace(\"'\",\"\").split(', '):\n",
    "        if _ev not in liste_ev_unique_depeches:\n",
    "            liste_ev_unique_depeches.append(_ev)\n",
    "print(len(liste_ev_unique_depeches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16059\n"
     ]
    }
   ],
   "source": [
    "liste_ev_unique_photos = []\n",
    "for ev in photos.event:\n",
    "    for _ev in ev[1:-1].replace(\"'\",\"\").split(', '):\n",
    "        if _ev not in liste_ev_unique_photos:\n",
    "            liste_ev_unique_photos.append(_ev)\n",
    "print(len(liste_ev_unique_photos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Uno', 'caption', 'city', 'contributor', 'country',\n",
       "       'country_only', 'country_out', 'created', 'creator', 'dept',\n",
       "       'entity_company', 'entity_departement', 'entity_faces',\n",
       "       'entity_function', 'entity_keyword', 'entity_location', 'entity_media',\n",
       "       'entity_organisation', 'entity_person', 'entity_region', 'entity_video',\n",
       "       'event', 'expires', 'genre', 'headline', 'iptc', 'keyword', 'language',\n",
       "       'mediatopic', 'newsItemID', 'product', 'provider', 'published_date',\n",
       "       'region', 'revision', 'rules', 'signal', 'slug', 'source', 'status',\n",
       "       'title', 'topic', 'urgency', 'url_extracted'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "photos.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153262"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = 0 \n",
    "for k in photos.caption: \n",
    "    if len(k.split())>10 : \n",
    "        c+=1\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([     0,     12,     13,     14,     20,     22,     27,     33,\n",
       "                34,     37,\n",
       "            ...\n",
       "            360975, 360977, 360978, 360980, 360982, 360984, 360987, 360988,\n",
       "            360989, 360991],\n",
       "           dtype='int64', length=153292)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "photos.index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'President of the European Commission Ursula von der Leyen gestures during a special European Council summit in Brussels on February 20, 2020, held to discuss the next long-term budget of the European Union (EU). '"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "photos.caption[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(245475, 45)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "photos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150536, 45)\n"
     ]
    }
   ],
   "source": [
    "def author_del_photos(text):\n",
    "    text_s = text\n",
    "    while(text_s[-7:] != ' / AFP ' and len(text_s) > 1): \n",
    "        text_s = text_s[:-1]\n",
    "    if(len(text_s) <= 1):\n",
    "        return(text)\n",
    "    return(text_s[:-7])\n",
    "photos.caption = photos.caption.apply(author_del_photos)          \n",
    "photos.drop_duplicates(subset='caption', keep='first', inplace=True)\n",
    "\n",
    "print(photos.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ya/miniconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: spacy.morphology.Morphology size changed, may indicate binary incompatibility. Expected 104 from C header, got 112 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/Users/ya/miniconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: spacy.vocab.Vocab size changed, may indicate binary incompatibility. Expected 96 from C header, got 104 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import spacy \n",
    "import neuralcoref\n",
    "\n",
    "#Toute cette cellule est issue de l'autre notebook (création du csv) et permet donc d'avoir toutes les fonctions\n",
    "#définies dans ce dernier à disposition.\n",
    "\n",
    "\n",
    "#On importe le fichier contenant les scores de chaque fonction grammaticale\n",
    "scoring = pd.read_csv('scoring.csv', delimiter = \";\")\n",
    "dict_val = {}\n",
    "\n",
    "for i in range(48):\n",
    "    dict_val[scoring['function'][i]] = scoring['score_norm'][i]\n",
    "\n",
    "#On importe un modèle md pour avoir des mots vectorisés\n",
    "nlp=spacy.load(\"en_core_web_md\")  \n",
    "neuralcoref.add_to_pipe(nlp,greedyness=0.5)\n",
    "\n",
    "def dep_ent(ent, doc):\n",
    "    \"\"\" Retourne la fonction grammaticale :  la 'dep', d'une entité. Cette fonction est nécessaire car elle permet d'affecter\n",
    "    une dep à une entité composée de plusieurs mots ayant chacun une dep de base.\n",
    "    Traite aussi le cas particulier des mots étant des conj ou des compound : leur vrai dep et celle du mot auxquels\n",
    "    ils sont associés en tant que conj ou compound.\"\"\"\n",
    "    start= ent.start\n",
    "    end=ent.end\n",
    "    for k in range(start,end):\n",
    "        if doc[k].head.text not in ent.text: \n",
    "            if doc[k].dep_=='conj':     \n",
    "                tok=doc[k]            \n",
    "                while tok.dep_=='conj':\n",
    "                    tok=tok.head      \n",
    "                return(tok.dep_)\n",
    "            \n",
    "            if doc[k].dep_=='compound':   \n",
    "                tok=doc[k]            \n",
    "                while tok.dep_=='compound':\n",
    "                    tok=tok.head      \n",
    "                return(tok.dep_)\n",
    "            return(doc[k].dep_)    \n",
    "    return doc[start].dep_\n",
    "\n",
    "def ent_good_type(ent): #filtre les entités selon leur type\n",
    "    return (ent.label_ == \"PERSON\"or ent.label_ == \"NORP\" or ent.label_ == \"ORG\" or ent.label_ == \"GPE\" or ent.label_ == \"EVENT\" or ent.label_ == \"LOC\")\n",
    "\n",
    "def sort_ent(doc):\n",
    "    \"\"\"Retourne la liste des entités en les filtrant selon leur type et en les triant de manière à avoir au début de\n",
    "    la liste les entités ayant des coréférences.\"\"\"\n",
    "    ent_coref=[ent for ent in doc.ents if ent._.is_coref and ent_good_type(ent)]\n",
    "    ent_vanilla=[ent for ent in doc.ents if ent_good_type(ent) and not ent._.is_coref]\n",
    "    return ent_coref + ent_vanilla\n",
    "\n",
    "def scores_doc(doc):\n",
    "    \"\"\"Retourne le score de chaque entité pour la méthode sans neuralcoref.\"\"\"\n",
    "    res={}\n",
    "    for ent in doc.ents:\n",
    "        if ent.text not in res.keys():\n",
    "            res[ent.text]=dict_val[dep_ent(ent,doc)]\n",
    "        else:\n",
    "            res[ent.text]+=dict_val[dep_ent(ent,doc)]\n",
    "    return res\n",
    "\n",
    "def scores_doc_coref1(doc):\n",
    "    \"\"\"Retourne le score de chaque entité pour la méthode de base opérée sur le document resolved.\n",
    "    Le document resolved est le document de base dans lequel toutes les références à un groupe de mot sont remplacées\n",
    "    par celui-ci.\n",
    "    Par exemple : My dad is home. He watches TV devient My dad is home. My dad watches TV.\n",
    "    En raisonnant avec le nlp sur le document resolved, le nlp va détecter beaucoup plus de fois la même entité.\n",
    "    Le principal inconvénient est que toutes les références sont remplacées, y compris celles qui ne sont pas associées \n",
    "    à des entités mais plutôt à des très longs bouts de phrase qui sont repris par un pronom comme \"it\"  \"\"\"\n",
    "    \n",
    "    doc=nlp(doc._.coref_resolved)\n",
    "    res={}\n",
    "    for ent in doc.ents:\n",
    "        if ent_good_type(ent):\n",
    "            if ent.text not in res.keys():\n",
    "                res[ent.text]=dict_val[dep_ent(ent,doc)]\n",
    "            else:\n",
    "                res[ent.text]+=dict_val[dep_ent(ent,doc)]\n",
    "    return res\n",
    "\n",
    "def is_in_cluster(ent,cluster):  #détermine si une entité est dans une des mentions d'un cluster\n",
    "    for span in cluster.mentions:\n",
    "        if ent.text in span.text:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "\n",
    "def scores_doc_coref2(doc):\n",
    "    \"\"\"Cette méthode utilise neuralcoref mais au lieu d'agir sur le doc resolved, on va chercher a l'interieur des clusters\n",
    "    associés au document. Pour rappel, un cluster contient un mot et ses références. Ce mot n'est pas forcément une entité.\n",
    "    Un cluster est de la forme Trump : [Trump, he].\n",
    "    Pour chaque entité, on va d'abord regarder si elle est coréférencée (donc mentionnée explicitement dans un cluster)\n",
    "    ou pas.\n",
    "    Si elle est coréférencée, on va chercher le cluster qui lui est associé.\n",
    "    Une fois dans ce cluster, on va regarder pour chaque mention (réf à l'entité) si elle contient ou pas des entités.\n",
    "    Si c'est le cas, on va alors indiquer que cette entité ne doit pas être retraitée par la suite car elle est traitée en\n",
    "    tant qu'autre mention de l'entité que l'on traite actuellement.\n",
    "    Par exemple, pour l'entité référencée Trump, on trouve le cluster suivant : Trump : [Trump, Donald Trump, he].\n",
    "    Alors l'entité Donald Trump va être marquée comme traitée car elle est en fait équivalente à Trump.\n",
    "    \"he\" n'étant pas une entité on a pas ce pb pour cette mention la.\n",
    "    Ensuite on calcule le score de chaque mention (Trump, Donald Trump et he) en se basant sur leur fonction grammaticale.\n",
    "    Puis on ajoute ces scores à celui de l'entité de base (Trump).\n",
    "    \n",
    "    Si l'entité de base n'est pas référencée, c'est un peu le même principe, la seule complexité en plus étant le fait que\n",
    "    l'entité n'est pas forcément mentionnée telle quelle dans les mentions d'un cluster. \n",
    "    Par exemple, si notre entité de base est Sienna Miller, il est possible qu'on ait un cluster de la forme\n",
    "    The british actress Sienna Miller : [The british actress Sienna Miller, she].\n",
    "    Dans ce cas il faut rechercher si chaque mention contient l'entité de base avant de procéder comme pour les \n",
    "    entités référencées.\n",
    "    \n",
    "    \"\"\"\n",
    "    clusters=doc._.coref_clusters  #liste des clusters du doc. \n",
    "    res={} #le resultat sera un dictionnaire qui permet d'associer un score à chque entité\n",
    "    ent_treated={} #dictionnaire pour différencier les entités traitées des autres\n",
    "    ents_sorted=sort_ent(doc)  #on place les entités ayant une coref avant les autres\n",
    "    for ent in ents_sorted:   \n",
    "        ent_treated[ent.text]=0  #on initialise en affectant 0 à toutes les entités\n",
    "\n",
    "    for ent in ents_sorted:     #pour chaque entité\n",
    "        if ent_treated[ent.text]==0: #si elle n'est pas considérée comme \"traitée\"\n",
    "            if ent._.is_coref:  #si elle est coréférencée (donc si elle apparait en tant que mention pour un cluster )\n",
    "                #print(ent)\n",
    "                for cluster in clusters:  #on va chercher le cluster associé à l'entité puisqu'elle est coref\n",
    "                    if ent in cluster.mentions: # on regarde si l'entité est dans les mentions du cluster\n",
    "                        for span in cluster.mentions: #Mtnt qu'on est dans le bon cluster, on regarde pour chaque span\n",
    "                            if span.ents != [] : \n",
    "                                if ent.has_vector:\n",
    "                                    max_sim=0\n",
    "                                    max_span_ent=span.ents[0]\n",
    "                                    for span_ent in span.ents: #on cherche l'entité dans le span la plus proche de ent\n",
    "                                        if span_ent.has_vector:\n",
    "                                            if ent.similarity(span_ent) > max_sim:\n",
    "                                                max_span_ent=span_ent\n",
    "                                                max_sim=ent.similarity(span_ent)\n",
    "                                    ent_treated[max_span_ent.text]=1 #une fois qu'on l'a trouvé on la marque comme traitée\n",
    "                            else:\n",
    "                                max_span_ent=span        \n",
    "                            if ent.text not in res.keys(): \n",
    "                                res[ent.text]=dict_val[dep_ent(max_span_ent,doc)]  #on affecte le score de l'entité\n",
    "                            else:\n",
    "                                res[ent.text] += dict_val[dep_ent(max_span_ent,doc)] \n",
    "            else: #si l'entité n'est pas exactement coréférencée par neuralcoref\n",
    "                flag=0\n",
    "                for cluster in clusters:\n",
    "                    if is_in_cluster(ent,cluster) and ent.label_ != 'NORP': \n",
    "                        flag=1\n",
    "                        for span in cluster.mentions:\n",
    "                            #print(span)\n",
    "                            if span.ents != [] :\n",
    "                                if ent.has_vector:\n",
    "                                    max_sim=0\n",
    "                                    max_span_ent=span.ents[0]\n",
    "                                    for span_ent in span.ents:\n",
    "                                        if span_ent.has_vector:\n",
    "                                            if ent.similarity(span_ent) > max_sim:\n",
    "                                                max_span_ent=span_ent\n",
    "                                                max_sim=ent.similarity(span_ent)\n",
    "                                    ent_treated[max_span_ent.text]=1\n",
    "                            if ent.text not in res.keys():\n",
    "                                res[ent.text]=dict_val[dep_ent(span,doc)] #...replacer max_span_ent par span ici\n",
    "                            else:\n",
    "                                res[ent.text] += dict_val[dep_ent(span,doc)]  #et ici\n",
    "                if flag==0: #si l'entité n'est vraiment dans aucun cluster   \n",
    "                    if ent.text not in res.keys():\n",
    "                        res[ent.text]=dict_val[dep_ent(ent,doc)]\n",
    "                    else:\n",
    "                        res[ent.text]+=dict_val[dep_ent(ent,doc)] \n",
    "    return res\n",
    "\n",
    "\n",
    "def freq_dict(L):\n",
    "    n = len(L)\n",
    "    L_unique = list(set(L))\n",
    "    d = {}\n",
    "    for a in L_unique:\n",
    "        for b in L:\n",
    "            if a == b:\n",
    "                if a in d.keys():\n",
    "                    d[a] += 1/n\n",
    "                else:\n",
    "                    d[a] = 1/n\n",
    "    return(d)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ya/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61a2ecb9ca7b43d3a43c07e119472c0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=150536.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "\n",
    "\n",
    "NLP = [nlp(dep) for dep in tqdm_notebook(photos.caption)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ya/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fa99e35182f4c5a84e78e8ba11de5d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=150536.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#scores_photos2 = [scores_doc_coref2(N) for N in tqdm_notebook(NLP)]\n",
    "scores_photos1 = [scores_doc_coref1(N) for N in tqdm_notebook(NLP)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Austria': 0.38297872299999997,\n",
       " 'Sebastian Kurz': 0.46808510600000003,\n",
       " 'Luxembourg': 0.38297872299999997,\n",
       " 'Xavier Bettel': 1.0,\n",
       " 'European Council': 0.8297872340000001,\n",
       " 'Brussels': 0.8297872340000001,\n",
       " 'the European Union': 0.8297872340000001,\n",
       " 'EU': 0.46808510600000003}"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_photos1[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ya/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:17: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dd81b695b444c2f83953dd299e93168",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=150536.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#global_ent_list = [[ent.text for ent in descr.ents if ent_good_type(ent)] for descr in tqdm_notebook(NLP)]\n",
    "\n",
    "def freq_dict(L):\n",
    "    n = len(L)\n",
    "    L_unique = list(set(L))\n",
    "    d = {}\n",
    "    for a in L_unique:\n",
    "        for b in L:\n",
    "            if a == b:\n",
    "                if a in d.keys():\n",
    "                    d[a] += 1/n\n",
    "                else:\n",
    "                    d[a] = 1/n\n",
    "    return(d)\n",
    "\n",
    "global_freq_list = [freq_dict(L) for L in tqdm_notebook(global_ent_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ya/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e49966b72954ee888ae36abac189d82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=150536.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "150536"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_list_str1=[str(dic) for dic in tqdm_notebook(scores_photos1)]\n",
    "#score_list_str2=[str(dic) for dic in tqdm(score_photos2)]\n",
    "\n",
    "freq_list_str=[str(dic) for  dic in global_freq_list]\n",
    "len(freq_list_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores1=pd.DataFrame({'caption':photos.caption,'scores':score_list_str1,'freq':freq_list_str})\n",
    "df_scores1.to_csv(\"scores_freq_photos1.csv\",index=False)\n",
    "#df_scores2=pd.DataFrame({'description':photos.caption,'scores':score_list_str2,'freq':freq_list_str})\n",
    "#df_scores2.to_csv(\"scores_freq_photos2.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>caption</th>\n",
       "      <th>scores</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Portugal's Prime Minister Antonio Costa (2ndL)...</td>\n",
       "      <td>{'Portugal': 0.38297872299999997, 'Antonio Cos...</td>\n",
       "      <td>{'the European Council': 0.125, 'European Coun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>President of the European Commission Ursula vo...</td>\n",
       "      <td>{'the European Commission': 0.8297872340000001...</td>\n",
       "      <td>{'the European Commission': 0.1666666666666666...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Denmark's Prime Minister Mette Frederiksen (L)...</td>\n",
       "      <td>{'Denmark': 0.38297872299999997, 'Mette Freder...</td>\n",
       "      <td>{'Denmark': 0.125, 'the European Council': 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Police officers put up a vision barries in fro...</td>\n",
       "      <td>{'Hanau': 1.6595744680000002, 'Germany': 1.297...</td>\n",
       "      <td>{'Hanau': 0.3333333333333333, 'Germany': 0.333...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Denmark's Prime Minister Mette Frederiksen att...</td>\n",
       "      <td>{'Denmark': 0.38297872299999997, 'Mette Freder...</td>\n",
       "      <td>{'Denmark': 0.16666666666666666, 'European Cou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              caption  \\\n",
       "0   Portugal's Prime Minister Antonio Costa (2ndL)...   \n",
       "12  President of the European Commission Ursula vo...   \n",
       "13  Denmark's Prime Minister Mette Frederiksen (L)...   \n",
       "14  Police officers put up a vision barries in fro...   \n",
       "20  Denmark's Prime Minister Mette Frederiksen att...   \n",
       "\n",
       "                                               scores  \\\n",
       "0   {'Portugal': 0.38297872299999997, 'Antonio Cos...   \n",
       "12  {'the European Commission': 0.8297872340000001...   \n",
       "13  {'Denmark': 0.38297872299999997, 'Mette Freder...   \n",
       "14  {'Hanau': 1.6595744680000002, 'Germany': 1.297...   \n",
       "20  {'Denmark': 0.38297872299999997, 'Mette Freder...   \n",
       "\n",
       "                                                 freq  \n",
       "0   {'the European Council': 0.125, 'European Coun...  \n",
       "12  {'the European Commission': 0.1666666666666666...  \n",
       "13  {'Denmark': 0.125, 'the European Council': 0.1...  \n",
       "14  {'Hanau': 0.3333333333333333, 'Germany': 0.333...  \n",
       "20  {'Denmark': 0.16666666666666666, 'European Cou...  "
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scores1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "score_photos = pd.read_csv(\"scores_freq_photos1.csv\")\n",
    "score_depeches = pd.read_csv(\"scores_freq_depeches.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scores</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{}</td>\n",
       "      <td>{'ISNA': 0.5, 'Iranian': 0.5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{}</td>\n",
       "      <td>{'Australia': 0.05405405405405406, 'Verreynne'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{}</td>\n",
       "      <td>{'Mahathir Mohamad': 0.14285714285714285, 'Anw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{}</td>\n",
       "      <td>{'Tottenham': 0.07142857142857142, 'Chelsea': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{}</td>\n",
       "      <td>{'the World Health Organization': 0.3333333333...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{}</td>\n",
       "      <td>{'Greek': 0.1111111111111111, 'Thessaloniki': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{}</td>\n",
       "      <td>{'US': 0.2222222222222222, 'Phil Hogan': 0.111...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{}</td>\n",
       "      <td>{'PAIGC': 0.2, 'Umaro Sissoco Embalo': 0.1, 'T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{}</td>\n",
       "      <td>{'SAS': 0.3333333333333333, 'Gustafson': 0.333...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{}</td>\n",
       "      <td>{'Extinction Rebellion': 0.3333333333333333, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{}</td>\n",
       "      <td>{'Charles': 0.125, 'Lindsay Hoyle': 0.125, 'th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{}</td>\n",
       "      <td>{'Alpha Conde': 0.05, 'Lansana Conte': 0.05, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{}</td>\n",
       "      <td>{'Alpha Conde': 0.07142857142857142, 'Kelefa S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>{}</td>\n",
       "      <td>{'Alpha Conde': 0.058823529411764705, 'Sorbonn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{}</td>\n",
       "      <td>{'San Siro': 0.125, 'UEFA': 0.125, 'Europa Lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>{}</td>\n",
       "      <td>{'Switzerland': 0.07142857142857142, 'Vosskuhl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>{}</td>\n",
       "      <td>{'Danielle Wyatt': 0.041666666666666664, 'Heat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>{}</td>\n",
       "      <td>{'Tedros': 1.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>{}</td>\n",
       "      <td>{'Amanda Knox': 0.2, 'Italian': 0.2, 'US': 0.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>{}</td>\n",
       "      <td>{'China': 0.3333333333333333, 'Beijing': 0.666...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>{}</td>\n",
       "      <td>{'Australia': 0.2, 'South Africa': 0.2, 'New Z...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>{}</td>\n",
       "      <td>{'Gotabaya': 0.07692307692307693, 'the Human R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>{}</td>\n",
       "      <td>{'Du Hangwei': 0.5, 'China': 0.5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>{}</td>\n",
       "      <td>{'Fiat': 0.05555555555555555, 'US': 0.05555555...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>{}</td>\n",
       "      <td>{'Thanathorn Juangroongruangkit': 0.25, 'Futur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>{}</td>\n",
       "      <td>{'Japan': 0.25, 'Diamond Princess': 0.25, 'Hea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>{}</td>\n",
       "      <td>{'Venetian': 0.25, 'bme-ev': 0.25, 'Albania': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>{}</td>\n",
       "      <td>{'Palestinian': 0.125, 'al-Maliki': 0.125, 'th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>{}</td>\n",
       "      <td>{'Singapore': 0.6666666666666666, 'Chinese': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>{}</td>\n",
       "      <td>{'Burundi': 1.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19945</th>\n",
       "      <td>{}</td>\n",
       "      <td>{'Americans': 0.023255813953488372, 'Arab': 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19946</th>\n",
       "      <td>{}</td>\n",
       "      <td>{'French': 0.25, 'Adele Haenel': 0.25, 'Paris'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19947</th>\n",
       "      <td>{}</td>\n",
       "      <td>{'Iraqi': 1.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19948</th>\n",
       "      <td>{}</td>\n",
       "      <td>{'German': 0.14285714285714285, 'the United St...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19949</th>\n",
       "      <td>{}</td>\n",
       "      <td>{\"Roman Polanski's\": 0.05263157894736842, \"Hir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19950</th>\n",
       "      <td>{}</td>\n",
       "      <td>{'Chinese': 0.2222222222222222, 'US': 0.111111...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19951</th>\n",
       "      <td>{}</td>\n",
       "      <td>{'EU': 0.2, 'Asia': 0.2, 'Europe': 0.2, 'Europ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19952</th>\n",
       "      <td>{}</td>\n",
       "      <td>{'HP Inc.': 0.1111111111111111, 'Dave Packard'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19953</th>\n",
       "      <td>{}</td>\n",
       "      <td>{'Joseph': 0.018867924528301886, 'R. Chase': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19954</th>\n",
       "      <td>{}</td>\n",
       "      <td>{'West Indies': 0.16666666666666666, 'Shai Hop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19955</th>\n",
       "      <td>{}</td>\n",
       "      <td>{'Zelensky': 0.16666666666666666, 'Donald Trum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19956</th>\n",
       "      <td>{}</td>\n",
       "      <td>{'Palestinian': 0.25, 'the United Nations': 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19957</th>\n",
       "      <td>{}</td>\n",
       "      <td>{'Dutch': 0.4, 'IJmuiden': 0.2, 'Britain': 0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19958</th>\n",
       "      <td>{}</td>\n",
       "      <td>{\"Martine Beckers'\": 0.5, 'Rwanda': 0.5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19959</th>\n",
       "      <td>{}</td>\n",
       "      <td>{'Liverpool': 0.06666666666666667, 'Sean': 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19960</th>\n",
       "      <td>{}</td>\n",
       "      <td>{'Manchester United': 0.06666666666666667, 'Li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19961</th>\n",
       "      <td>{}</td>\n",
       "      <td>{'German': 0.07142857142857142, 'Olympiakos': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19962</th>\n",
       "      <td>{}</td>\n",
       "      <td>{'FIFA': 0.375, \"the Iraqi federation's\": 0.12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19963</th>\n",
       "      <td>{}</td>\n",
       "      <td>{'San Francisco': 0.05555555555555555, 'Ninten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19964</th>\n",
       "      <td>{}</td>\n",
       "      <td>{'Mark Thompson': 0.125, 'US': 0.125, 'The New...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19965</th>\n",
       "      <td>{}</td>\n",
       "      <td>{'Greek': 0.08695652173913043, 'Turkey': 0.217...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19966</th>\n",
       "      <td>{}</td>\n",
       "      <td>{'International Criminal Court': 0.05263157894...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19967</th>\n",
       "      <td>{}</td>\n",
       "      <td>{'ECB': 0.5, 'German': 0.5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19968</th>\n",
       "      <td>{}</td>\n",
       "      <td>{'Iran': 0.16666666666666666, 'the Iranian ato...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19969</th>\n",
       "      <td>{}</td>\n",
       "      <td>{'Brazil': 1.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19970</th>\n",
       "      <td>{}</td>\n",
       "      <td>{'GE Aviation': 0.05555555555555555, 'Maurizio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19971</th>\n",
       "      <td>{}</td>\n",
       "      <td>{'Andrej Babis': 0.25, 'Plaga': 0.25, 'the Cze...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19972</th>\n",
       "      <td>{}</td>\n",
       "      <td>{'Sattawat Hiranburana': 0.2, 'American': 0.4,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19973</th>\n",
       "      <td>{}</td>\n",
       "      <td>{'Hollywood': 0.05555555555555555, 'Belloubet'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19974</th>\n",
       "      <td>{}</td>\n",
       "      <td>{'North Korea': 0.07692307692307693, 'US': 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19975 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      scores                                               freq\n",
       "0         {}                      {'ISNA': 0.5, 'Iranian': 0.5}\n",
       "1         {}  {'Australia': 0.05405405405405406, 'Verreynne'...\n",
       "2         {}  {'Mahathir Mohamad': 0.14285714285714285, 'Anw...\n",
       "3         {}  {'Tottenham': 0.07142857142857142, 'Chelsea': ...\n",
       "4         {}  {'the World Health Organization': 0.3333333333...\n",
       "5         {}  {'Greek': 0.1111111111111111, 'Thessaloniki': ...\n",
       "6         {}  {'US': 0.2222222222222222, 'Phil Hogan': 0.111...\n",
       "7         {}  {'PAIGC': 0.2, 'Umaro Sissoco Embalo': 0.1, 'T...\n",
       "8         {}  {'SAS': 0.3333333333333333, 'Gustafson': 0.333...\n",
       "9         {}  {'Extinction Rebellion': 0.3333333333333333, '...\n",
       "10        {}  {'Charles': 0.125, 'Lindsay Hoyle': 0.125, 'th...\n",
       "11        {}  {'Alpha Conde': 0.05, 'Lansana Conte': 0.05, '...\n",
       "12        {}  {'Alpha Conde': 0.07142857142857142, 'Kelefa S...\n",
       "13        {}  {'Alpha Conde': 0.058823529411764705, 'Sorbonn...\n",
       "14        {}  {'San Siro': 0.125, 'UEFA': 0.125, 'Europa Lea...\n",
       "15        {}  {'Switzerland': 0.07142857142857142, 'Vosskuhl...\n",
       "16        {}  {'Danielle Wyatt': 0.041666666666666664, 'Heat...\n",
       "17        {}                                    {'Tedros': 1.0}\n",
       "18        {}  {'Amanda Knox': 0.2, 'Italian': 0.2, 'US': 0.4...\n",
       "19        {}  {'China': 0.3333333333333333, 'Beijing': 0.666...\n",
       "20        {}  {'Australia': 0.2, 'South Africa': 0.2, 'New Z...\n",
       "21        {}  {'Gotabaya': 0.07692307692307693, 'the Human R...\n",
       "22        {}                  {'Du Hangwei': 0.5, 'China': 0.5}\n",
       "23        {}  {'Fiat': 0.05555555555555555, 'US': 0.05555555...\n",
       "24        {}  {'Thanathorn Juangroongruangkit': 0.25, 'Futur...\n",
       "25        {}  {'Japan': 0.25, 'Diamond Princess': 0.25, 'Hea...\n",
       "26        {}  {'Venetian': 0.25, 'bme-ev': 0.25, 'Albania': ...\n",
       "27        {}  {'Palestinian': 0.125, 'al-Maliki': 0.125, 'th...\n",
       "28        {}  {'Singapore': 0.6666666666666666, 'Chinese': 0...\n",
       "29        {}                                   {'Burundi': 1.0}\n",
       "...      ...                                                ...\n",
       "19945     {}  {'Americans': 0.023255813953488372, 'Arab': 0....\n",
       "19946     {}  {'French': 0.25, 'Adele Haenel': 0.25, 'Paris'...\n",
       "19947     {}                                     {'Iraqi': 1.0}\n",
       "19948     {}  {'German': 0.14285714285714285, 'the United St...\n",
       "19949     {}  {\"Roman Polanski's\": 0.05263157894736842, \"Hir...\n",
       "19950     {}  {'Chinese': 0.2222222222222222, 'US': 0.111111...\n",
       "19951     {}  {'EU': 0.2, 'Asia': 0.2, 'Europe': 0.2, 'Europ...\n",
       "19952     {}  {'HP Inc.': 0.1111111111111111, 'Dave Packard'...\n",
       "19953     {}  {'Joseph': 0.018867924528301886, 'R. Chase': 0...\n",
       "19954     {}  {'West Indies': 0.16666666666666666, 'Shai Hop...\n",
       "19955     {}  {'Zelensky': 0.16666666666666666, 'Donald Trum...\n",
       "19956     {}  {'Palestinian': 0.25, 'the United Nations': 0....\n",
       "19957     {}  {'Dutch': 0.4, 'IJmuiden': 0.2, 'Britain': 0.2...\n",
       "19958     {}           {\"Martine Beckers'\": 0.5, 'Rwanda': 0.5}\n",
       "19959     {}  {'Liverpool': 0.06666666666666667, 'Sean': 0.1...\n",
       "19960     {}  {'Manchester United': 0.06666666666666667, 'Li...\n",
       "19961     {}  {'German': 0.07142857142857142, 'Olympiakos': ...\n",
       "19962     {}  {'FIFA': 0.375, \"the Iraqi federation's\": 0.12...\n",
       "19963     {}  {'San Francisco': 0.05555555555555555, 'Ninten...\n",
       "19964     {}  {'Mark Thompson': 0.125, 'US': 0.125, 'The New...\n",
       "19965     {}  {'Greek': 0.08695652173913043, 'Turkey': 0.217...\n",
       "19966     {}  {'International Criminal Court': 0.05263157894...\n",
       "19967     {}                        {'ECB': 0.5, 'German': 0.5}\n",
       "19968     {}  {'Iran': 0.16666666666666666, 'the Iranian ato...\n",
       "19969     {}                                    {'Brazil': 1.0}\n",
       "19970     {}  {'GE Aviation': 0.05555555555555555, 'Maurizio...\n",
       "19971     {}  {'Andrej Babis': 0.25, 'Plaga': 0.25, 'the Cze...\n",
       "19972     {}  {'Sattawat Hiranburana': 0.2, 'American': 0.4,...\n",
       "19973     {}  {'Hollywood': 0.05555555555555555, 'Belloubet'...\n",
       "19974     {}  {'North Korea': 0.07692307692307693, 'US': 0.0...\n",
       "\n",
       "[19975 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_depeches"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
