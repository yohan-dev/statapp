{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\maison\\appdata\\local\\programs\\python\\python36\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: spacy.morphology.Morphology size changed, may indicate binary incompatibility. Expected 104 from C header, got 112 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "c:\\users\\maison\\appdata\\local\\programs\\python\\python36\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: spacy.vocab.Vocab size changed, may indicate binary incompatibility. Expected 96 from C header, got 104 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\Maison\\AppData\\Roaming\\Python\\Python36\\site-packages\\IPython\\core\\interactiveshell.py:3049: DtypeWarning: Columns (10,15,17,23,24,29,30,37) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import neuralcoref\n",
    "import ast\n",
    "import random\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "depeches = pd.read_csv(\"depeches.csv\")\n",
    "photos = pd.read_csv(\"photos.csv\",encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x24f11fd7e80>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp=spacy.load(\"en_core_web_md\")  \n",
    "neuralcoref.add_to_pipe(nlp,greedyness=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DÃ©commenter votre partie\n",
    "#ton_chiffre = 1 # Dimitri\n",
    "#ton_chiffre = 2 # Louis\n",
    "#ton_chiffre = 3 # Yannis\n",
    "#ton_chiffre = 4 # Yohan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maison\\AppData\\Roaming\\Python\\Python36\\site-packages\\ipykernel_launcher.py:1: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80ad4c2ba04a4f37b8c743254da07bdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=360999.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nlp_photos = []\n",
    "#for i in tqdm_notebook(range(100000)): # Dimitri\n",
    "#    nlp_photos.append(nlp(photos.caption[i]))\n",
    "#for i in tqdm_notebook(range(100000,200000)): # Louis\n",
    "#    nlp_photos.append(nlp(photos.caption[i]))\n",
    "#for i in tqdm_notebook(range(200000,300000)): # Yannis\n",
    "#    nlp_photos.append(nlp(photos.caption[i]))\n",
    "#for i in tqdm_notebook(range(300000, photos.shape[0])): # Yohan\n",
    "#    nlp_photos.append(nlp(photos.caption[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mentioned(ent, cluster):\n",
    "    for mention in cluster.mentions:\n",
    "        if(ent.text in mention.text):\n",
    "            return(True)\n",
    "ents_dict = []\n",
    "for document in nlp_photos:\n",
    "    dictionary = {}\n",
    "    for ent in document.ents:\n",
    "        dep_list = []\n",
    "        start = ent.start\n",
    "        end = ent.end\n",
    "        for i in range(start,end):\n",
    "            word = document[i]\n",
    "            if(word.head.text not in ent.text and (word.dep_ == 'compound' or word.dep_ == 'conj')):\n",
    "                while(word.dep_ == 'compound' or word.dep_ == 'conj'):\n",
    "                    word = word.head\n",
    "                dep_list.append(word.dep_)\n",
    "            else:\n",
    "                dep_list.append(word.dep_)\n",
    "        if(ent.text in dictionary.keys()):\n",
    "            dictionary[ent.text] += dep_list\n",
    "        else:\n",
    "            dictionary[ent.text] = dep_list\n",
    "    ents_dict.append(dictionary)\n",
    "corefs_dict = []\n",
    "for document in nlp_photos:\n",
    "    dictionary = {}\n",
    "    clusters = document._.coref_clusters\n",
    "    for ent in document.ents:\n",
    "        corefs_list = []\n",
    "        for cluster in clusters:\n",
    "            if(mentioned(ent,cluster)):\n",
    "                for mention in cluster.mentions:\n",
    "                    mention_deps = []\n",
    "                    start = mention.start\n",
    "                    end = mention.end\n",
    "                    for i in range(start,end):\n",
    "                        word = document[i]\n",
    "                        if(word.head.text not in mention.text and (word.dep_ == 'compound' or word.dep_ == 'conj')):\n",
    "                            while(word.dep_ == 'compound' or word.dep_ == 'conj'):\n",
    "                                word = word.head\n",
    "                            mention_deps.append(word.dep_)\n",
    "                        else:\n",
    "                            mention_deps.append(word.dep_)\n",
    "                    corefs_list.append((mention.text, mention_deps))     \n",
    "        if(ent.text not in dictionary.keys()):\n",
    "            dictionary[ent.text] = corefs_list\n",
    "    corefs_dict.append(dictionary)\n",
    "labels_dict = []\n",
    "for document in nlp_photos:\n",
    "    dictionary = {}\n",
    "    for ent in document.ents:\n",
    "        if(ent.text not in dictionary.keys()):\n",
    "            dictionary[ent.text] = [ent.label_]\n",
    "        else:\n",
    "            dictionary[ent.text] += [ent.label_]\n",
    "    labels_dict.append(dictionary)\n",
    "final_dataframe = pd.DataFrame({'Labels' : labels_dict, 'Ents' : ents_dict, 'Corefs' : corefs_dict})\n",
    "final_dataframe.to_pickle('final_dataframe_photos'+'_'+str(ton_chiffre)+'.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
