{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>scores</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US-British actress Sienna Miller poses after u...</td>\n",
       "      <td>{'US': 0.978723404, 'British': 0.978723404, 'S...</td>\n",
       "      <td>{'France': 0.16666666666666666, 'British': 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>People gather at a shopping mall in the Shatin...</td>\n",
       "      <td>{'Shatin': 0.8297872340000001, 'Hong Kong': 1....</td>\n",
       "      <td>{'Hong Kong': 0.5, 'Shatin': 0.5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AFP presents a photo essay of 19 images by pho...</td>\n",
       "      <td>{'AFP': 1.0, 'Christof Stache': 0.829787234000...</td>\n",
       "      <td>{'AFP': 0.25, 'Slug GERMANY-AGRICULTURE-CATTLE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A Palestinian worker harvests dates in the Jor...</td>\n",
       "      <td>{'Palestinian': 0.489361702, 'Jordan Valley': ...</td>\n",
       "      <td>{'West Bank': 0.07142857142857142, \"the West B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Turkish Trade Minister Ruhsar Pekcan (R) and U...</td>\n",
       "      <td>{'Turkish': 0.489361702, 'Ruhsar Pekcan': 0.93...</td>\n",
       "      <td>{'Commerce': 0.16666666666666666, 'Ruhsar Pekc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description  \\\n",
       "0  US-British actress Sienna Miller poses after u...   \n",
       "1  People gather at a shopping mall in the Shatin...   \n",
       "2  AFP presents a photo essay of 19 images by pho...   \n",
       "3  A Palestinian worker harvests dates in the Jor...   \n",
       "4  Turkish Trade Minister Ruhsar Pekcan (R) and U...   \n",
       "\n",
       "                                              scores  \\\n",
       "0  {'US': 0.978723404, 'British': 0.978723404, 'S...   \n",
       "1  {'Shatin': 0.8297872340000001, 'Hong Kong': 1....   \n",
       "2  {'AFP': 1.0, 'Christof Stache': 0.829787234000...   \n",
       "3  {'Palestinian': 0.489361702, 'Jordan Valley': ...   \n",
       "4  {'Turkish': 0.489361702, 'Ruhsar Pekcan': 0.93...   \n",
       "\n",
       "                                                freq  \n",
       "0  {'France': 0.16666666666666666, 'British': 0.1...  \n",
       "1                  {'Hong Kong': 0.5, 'Shatin': 0.5}  \n",
       "2  {'AFP': 0.25, 'Slug GERMANY-AGRICULTURE-CATTLE...  \n",
       "3  {'West Bank': 0.07142857142857142, \"the West B...  \n",
       "4  {'Commerce': 0.16666666666666666, 'Ruhsar Pekc...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import neuralcoref\n",
    "import ast\n",
    "import random\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "df1=pd.read_csv(\"scores1_freq.csv\")\n",
    "df2=pd.read_csv(\"scores2_freq.csv\")\n",
    "df1.head() #On vérifie que le fichier contient bien ce qu'il faut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Conversion des strings contenues dans le csv (colonnes score et fréquences) en dictionnaires\n",
    "\n",
    "liste_scores1=[]\n",
    "for string in df1.scores:\n",
    "    liste_scores1.append(ast.literal_eval(string))   \n",
    "\n",
    "liste_scores2=[]\n",
    "for string in df2.scores:\n",
    "    liste_scores2.append(ast.literal_eval(string))    \n",
    "\n",
    "liste_freq=[]\n",
    "for string in df1.freq:\n",
    "    liste_freq.append(ast.literal_eval(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Toute cette cellule est issue de l'autre notebook (création du csv) et permet donc d'avoir toutes les fonctions\n",
    "#définies dans ce dernier à disposition.\n",
    "\n",
    "\n",
    "#On importe le fichier contenant les scores de chaque fonction grammaticale\n",
    "scoring = pd.read_csv('scoring.csv', delimiter = \";\")\n",
    "dict_val = {}\n",
    "\n",
    "for i in range(48):\n",
    "    dict_val[scoring['function'][i]] = scoring['score_norm'][i]\n",
    "\n",
    "#On importe un modèle md pour avoir des mots vectorisés\n",
    "nlp=spacy.load(\"en_core_web_md\")  \n",
    "neuralcoref.add_to_pipe(nlp,greedyness=0.5)\n",
    "\n",
    "def dep_ent(ent, doc):\n",
    "    \"\"\" Retourne la fonction grammaticale :  la 'dep', d'une entité. Cette fonction est nécessaire car elle permet d'affecter\n",
    "    une dep à une entité composée de plusieurs mots ayant chacun une dep de base.\n",
    "    Traite aussi le cas particulier des mots étant des conj ou des compound : leur vrai dep et celle du mot auxquels\n",
    "    ils sont associés en tant que conj ou compound.\"\"\"\n",
    "    start= ent.start\n",
    "    end=ent.end\n",
    "    for k in range(start,end):\n",
    "        if doc[k].head.text not in ent.text: \n",
    "            if doc[k].dep_=='conj':     \n",
    "                tok=doc[k]            \n",
    "                while tok.dep_=='conj':\n",
    "                    tok=tok.head      \n",
    "                return(tok.dep_)\n",
    "            \n",
    "            if doc[k].dep_=='compound':   \n",
    "                tok=doc[k]            \n",
    "                while tok.dep_=='compound':\n",
    "                    tok=tok.head      \n",
    "                return(tok.dep_)\n",
    "            return(doc[k].dep_)    \n",
    "    return doc[start].dep_\n",
    "\n",
    "def ent_good_type(ent): #filtre les entités selon leur type\n",
    "    return (ent.label_ == \"PERSON\"or ent.label_ == \"NORP\" or ent.label_ == \"ORG\" or ent.label_ == \"GPE\" or ent.label_ == \"EVENT\" or ent.label_ == \"LOC\")\n",
    "\n",
    "def sort_ent(doc):\n",
    "    \"\"\"Retourne la liste des entités en les filtrant selon leur type et en les triant de manière à avoir au début de\n",
    "    la liste les entités ayant des coréférences.\"\"\"\n",
    "    ent_coref=[ent for ent in doc.ents if ent._.is_coref and ent_good_type(ent)]\n",
    "    ent_vanilla=[ent for ent in doc.ents if ent_good_type(ent) and not ent._.is_coref]\n",
    "    return ent_coref + ent_vanilla\n",
    "\n",
    "def scores_doc(doc):\n",
    "    \"\"\"Retourne le score de chaque entité pour la méthode sans neuralcoref.\"\"\"\n",
    "    res={}\n",
    "    for ent in doc.ents:\n",
    "        if ent.text not in res.keys():\n",
    "            res[ent.text]=dict_val[dep_ent(ent,doc)]\n",
    "        else:\n",
    "            res[ent.text]+=dict_val[dep_ent(ent,doc)]\n",
    "    return res\n",
    "\n",
    "def scores_doc_coref1(doc):\n",
    "    \"\"\"Retourne le score de chaque entité pour la méthode de base opérée sur le document resolved.\n",
    "    Le document resolved est le document de base dans lequel toutes les références à un groupe de mot sont remplacées\n",
    "    par celui-ci.\n",
    "    Par exemple : My dad is home. He watches TV devient My dad is home. My dad watches TV.\n",
    "    En raisonnant avec le nlp sur le document resolved, le nlp va détecter beaucoup plus de fois la même entité.\n",
    "    Le principal inconvénient est que toutes les références sont remplacées, y compris celles qui ne sont pas associées \n",
    "    à des entités mais plutôt à des très longs bouts de phrase qui sont repris par un pronom comme \"it\"  \"\"\"\n",
    "    \n",
    "    doc=nlp(doc._.coref_resolved)\n",
    "    res={}\n",
    "    for ent in doc.ents:\n",
    "        if ent_good_type(ent):\n",
    "            if ent.text not in res.keys():\n",
    "                res[ent.text]=dict_val[dep_ent(ent,doc)]\n",
    "            else:\n",
    "                res[ent.text]+=dict_val[dep_ent(ent,doc)]\n",
    "    return res\n",
    "\n",
    "def is_in_cluster(ent,cluster):  #détermine si une entité est dans une des mentions d'un cluster\n",
    "    for span in cluster.mentions:\n",
    "        if ent.text in span.text:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "\n",
    "def scores_doc_coref2(doc):\n",
    "    \"\"\"Cette méthode utilise neuralcoref mais au lieu d'agir sur le doc resolved, on va chercher a l'interieur des clusters\n",
    "    associés au document. Pour rappel, un cluster contient un mot et ses références. Ce mot n'est pas forcément une entité.\n",
    "    Un cluster est de la forme Trump : [Trump, he].\n",
    "    Pour chaque entité, on va d'abord regarder si elle est coréférencée (donc mentionnée explicitement dans un cluster)\n",
    "    ou pas.\n",
    "    Si elle est coréférencée, on va chercher le cluster qui lui est associé.\n",
    "    Une fois dans ce cluster, on va regarder pour chaque mention (réf à l'entité) si elle contient ou pas des entités.\n",
    "    Si c'est le cas, on va alors indiquer que cette entité ne doit pas être retraitée par la suite car elle est traitée en\n",
    "    tant qu'autre mention de l'entité que l'on traite actuellement.\n",
    "    Par exemple, pour l'entité référencée Trump, on trouve le cluster suivant : Trump : [Trump, Donald Trump, he].\n",
    "    Alors l'entité Donald Trump va être marquée comme traitée car elle est en fait équivalente à Trump.\n",
    "    \"he\" n'étant pas une entité on a pas ce pb pour cette mention la.\n",
    "    Ensuite on calcule le score de chaque mention (Trump, Donald Trump et he) en se basant sur leur fonction grammaticale.\n",
    "    Puis on ajoute ces scores à celui de l'entité de base (Trump).\n",
    "    \n",
    "    Si l'entité de base n'est pas référencée, c'est un peu le même principe, la seule complexité en plus étant le fait que\n",
    "    l'entité n'est pas forcément mentionnée telle quelle dans les mentions d'un cluster. \n",
    "    Par exemple, si notre entité de base est Sienna Miller, il est possible qu'on ait un cluster de la forme\n",
    "    The british actress Sienna Miller : [The british actress Sienna Miller, she].\n",
    "    Dans ce cas il faut rechercher si chaque mention contient l'entité de base avant de procéder comme pour les \n",
    "    entités référencées.\n",
    "    \n",
    "    \"\"\"\n",
    "    clusters=doc._.coref_clusters  #liste des clusters du doc. \n",
    "    res={} #le resultat sera un dictionnaire qui permet d'associer un score à chque entité\n",
    "    ent_treated={} #dictionnaire pour différencier les entités traitées des autres\n",
    "    ents_sorted=sort_ent(doc)  #on place les entités ayant une coref avant les autres\n",
    "    for ent in ents_sorted:   \n",
    "        ent_treated[ent.text]=0  #on initialise en affectant 0 à toutes les entités\n",
    "\n",
    "    for ent in ents_sorted:     #pour chaque entité\n",
    "        if ent_treated[ent.text]==0: #si elle n'est pas considérée comme \"traitée\"\n",
    "            if ent._.is_coref:  #si elle est coréférencée (donc si elle apparait en tant que mention pour un cluster )\n",
    "                #print(ent)\n",
    "                for cluster in clusters:  #on va chercher le cluster associé à l'entité puisqu'elle est coref\n",
    "                    if ent in cluster.mentions: # on regarde si l'entité est dans les mentions du cluster\n",
    "                        for span in cluster.mentions: #Mtnt qu'on est dans le bon cluster, on regarde pour chaque span\n",
    "                            if span.ents != [] : \n",
    "                                if ent.has_vector:\n",
    "                                    max_sim=0\n",
    "                                    max_span_ent=span.ents[0]\n",
    "                                    for span_ent in span.ents: #on cherche l'entité dans le span la plus proche de ent\n",
    "                                        if span_ent.has_vector:\n",
    "                                            if ent.similarity(span_ent) > max_sim:\n",
    "                                                max_span_ent=span_ent\n",
    "                                                max_sim=ent.similarity(span_ent)\n",
    "                                    ent_treated[max_span_ent.text]=1 #une fois qu'on l'a trouvé on la marque comme traitée\n",
    "                            else:\n",
    "                                max_span_ent=span        \n",
    "                            if ent.text not in res.keys(): \n",
    "                                res[ent.text]=dict_val[dep_ent(max_span_ent,doc)]  #on affecte le score de l'entité\n",
    "                            else:\n",
    "                                res[ent.text] += dict_val[dep_ent(max_span_ent,doc)] \n",
    "            else: #si l'entité n'est pas exactement coréférencée par neuralcoref\n",
    "                flag=0\n",
    "                for cluster in clusters:\n",
    "                    if is_in_cluster(ent,cluster) and ent.label_ != 'NORP': \n",
    "                        flag=1\n",
    "                        for span in cluster.mentions:\n",
    "                            #print(span)\n",
    "                            if span.ents != [] :\n",
    "                                if ent.has_vector:\n",
    "                                    max_sim=0\n",
    "                                    max_span_ent=span.ents[0]\n",
    "                                    for span_ent in span.ents:\n",
    "                                        if span_ent.has_vector:\n",
    "                                            if ent.similarity(span_ent) > max_sim:\n",
    "                                                max_span_ent=span_ent\n",
    "                                                max_sim=ent.similarity(span_ent)\n",
    "                                    ent_treated[max_span_ent.text]=1\n",
    "                            else:\n",
    "                                max_span_ent=span #on peut peut etre supprimer cette branche else et...\n",
    "                            if ent.text not in res.keys():\n",
    "                                res[ent.text]=dict_val[dep_ent(max_span_ent,doc)] #...replacer max_span_ent par span ici\n",
    "                            else:\n",
    "                                res[ent.text] += dict_val[dep_ent(max_span_ent,doc)]  #et ici\n",
    "                if flag==0: #si l'entité n'est vraiment dans aucun cluster   \n",
    "                    if ent.text not in res.keys():\n",
    "                        res[ent.text]=dict_val[dep_ent(ent,doc)]\n",
    "                    else:\n",
    "                        res[ent.text]+=dict_val[dep_ent(ent,doc)] \n",
    "    return res\n",
    "\n",
    "\n",
    "def freq_dict(L):\n",
    "    n = len(L)\n",
    "    L_unique = list(set(L))\n",
    "    d = {}\n",
    "    for a in L_unique:\n",
    "        for b in L:\n",
    "            if a == b:\n",
    "                if a in d.keys():\n",
    "                    d[a] += 1/n\n",
    "                else:\n",
    "                    d[a] = 1/n\n",
    "    return(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Les deux fonctions scores ci-dessous étaient les premières que nous avions écrites.\n",
    "\n",
    "def score_sim1(doc,score_doc,k):\n",
    "    \"\"\"Prend en paramètre un doc, le fichier de scores associés à ce doc et un entier k correspondant à l'indice de la \n",
    "    description avec laquelle on veut comparer le doc. Retourne le score de similarité entre le doc et la description.\n",
    "    Ici on calcule le score avec la méthode neuralcoref1 : on utilise liste_scores1.\"\"\"\n",
    "    res=0\n",
    "    freq_doc=freq_dict([ent.text for ent in doc.ents])\n",
    "    score_image=liste_scores1[k]\n",
    "    freq_image=liste_freq[k]\n",
    "    for i in score_doc.keys():\n",
    "        if i in score_image.keys():\n",
    "            res += (score_doc[i]+score_image[i])/2 - abs(freq_doc[i]-freq_image[i])/2\n",
    "    return res\n",
    "\n",
    "def score_sim2(doc,score_doc,k):\n",
    "    \"\"\"Prend en paramètre un doc, le fichier de scores associés à ce doc et un entier k correspondant à l'indice de la \n",
    "    description avec laquelle on veut comparer le doc. Retourne le score de similarité entre le doc et la description.\n",
    "    Ici on calcule le score avec la méthode neuralcoref2 : on utilise liste_scores2.\"\"\"\n",
    "    res=0\n",
    "    freq_doc=freq_dict([ent.text for ent in doc.ents])\n",
    "    score_image=liste_scores2[k]\n",
    "    freq_image=liste_freq[k]\n",
    "    for i in score_doc.keys():\n",
    "        if i in score_image.keys():\n",
    "            res += (score_doc[i]+score_image[i])/2 - abs(freq_doc[i]-freq_image[i])/2\n",
    "    return res\n",
    "\n",
    "\n",
    "#Dernière fonction score développée. Elle donne de meilleurs résultats.\n",
    "\n",
    "def score_sim3(doc,score_doc,k):\n",
    "    \"\"\"Prend en paramètre un doc, le fichier de scores associés à ce doc et un entier k correspondant à l'indice de la \n",
    "    description avec laquelle on veut comparer le doc. Retourne le score de similarité entre le doc et la description.\n",
    "    Ici on calcule le score avec la méthode neuralcoref1 : on utilise liste_scores1.\n",
    "    Par rapport aux fonctions précédentes, ici on a changé le calcul du score de similarité en \"normalisant\" les scores\n",
    "    du doc et de l'image, au lieu de les diviser par 2 (ce qui était inutile)\"\"\"\n",
    "    res=0\n",
    "    score_image=liste_scores1[k]\n",
    "    max_doc=max(score_doc.values())\n",
    "    max_im=max(score_image.values())\n",
    "    for i in score_doc.keys():\n",
    "        if i in score_image.keys():\n",
    "            if max_doc==0 or max_im==0:\n",
    "                return 0\n",
    "            res += score_doc[i]/max_doc +score_image[i]/max_im\n",
    "    return res\n",
    "\n",
    "\n",
    "def related_descr(doc):\n",
    "    \"\"\"Retourne la liste des indices correspondant aux descriptions ayant au moins 1 entité en commun avec le doc.\n",
    "    Permet d'effectuer moins de comparaison dans la fonction best_image.\"\"\"\n",
    "    index_list=[]\n",
    "    for k in range(len(liste_scores1)):\n",
    "        for ent in doc.ents:\n",
    "            if ent.text in liste_scores1[k].keys():\n",
    "                index_list.append(k)\n",
    "                break\n",
    "    return index_list\n",
    "\n",
    "def best_image1(doc):\n",
    "    \"\"\"Retourne l'indice de l'image dont la description correspond le plus au doc passé en paramètre.\n",
    "    La correspondance (matching) se fait avec score_sim1.\"\"\"\n",
    "    best_score=0\n",
    "    best_descr=0\n",
    "    score_doc=scores_doc_coref1(doc)\n",
    "    for k in related_descr(doc):\n",
    "        if score_sim1(doc,score_doc,k) > best_score:\n",
    "            best_score=score_sim1(doc,score_doc,k)\n",
    "            best_descr=k\n",
    "    return best_descr\n",
    "\n",
    "def best_image2(doc):\n",
    "    \"\"\"Retourne l'indice de l'image dont la description correspond le plus au doc passé en paramètre.\n",
    "    La correspondance (matching) se fait avec score_sim2.\"\"\"\n",
    "    score_doc=scores_doc_coref2(doc)\n",
    "    best_score=0\n",
    "    best_descr=0\n",
    "    for k in related_descr(doc):\n",
    "        if score_sim2(doc,score_doc,k) > best_score:\n",
    "            best_score=score_sim2(doc,score_doc,k)\n",
    "            best_descr=k\n",
    "    return best_descr\n",
    "\n",
    "def best_image3(doc):\n",
    "    \"\"\"Retourne l'indice de l'image dont la description correspond le plus au doc passé en paramètre.\n",
    "    La correspondance (matching) se fait avec score_sim3.\"\"\"\n",
    "    score_doc=scores_doc_coref1(doc)\n",
    "    best_score=0\n",
    "    best_descr=0\n",
    "    for k in related_descr(doc):\n",
    "        if score_sim3(doc,score_doc,k) > best_score:\n",
    "            best_score=score_sim3(doc,score_doc,k)\n",
    "            best_descr=k\n",
    "    return best_descr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[68298, 40293, 3466, 58103, 67638, 35801, 22853, 33636, 26733, 67719, 57352, 77063, 32114, 5974, 70629, 11646, 67801, 50471, 10573, 59194, 81196, 71611, 73512, 1074, 81853, 74660, 54325, 63637, 68800, 2890, 31012, 79269, 52566, 38580, 51315, 54471, 16366, 55348, 47501, 20884, 55982, 33281, 32674, 5708, 28431, 53544, 62748, 61686, 71576, 80723, 69064, 24722, 61944, 19753, 13854, 11466, 15963, 21806, 12000, 41225, 30044, 66182, 4728, 46890, 17706, 57062, 27190, 37619, 77393, 39063, 1625, 11292, 21873, 76304, 11662, 6449, 20544, 4150, 70076, 77159, 47505, 46607, 7857, 63422, 38167, 34983, 34135, 40650, 82191, 34269, 19311, 12463, 78595, 40638, 63480, 65039, 43343, 71759, 23813, 56833]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7475d273b87f444280f5ef6d53bab8ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3466 3945\n",
      "77063 76625\n",
      "11646 11723\n",
      "54325 43869\n",
      "61686 61884\n",
      "11466 11355\n",
      "27190 27127\n",
      "37619 35968\n",
      "1625 1515\n",
      "11292 8862\n",
      "11662 9592\n",
      "70076 25900\n",
      "77159 79316\n",
      "34983 8701\n",
      "82191 47126\n",
      "19311 19247\n",
      "12463 10770\n",
      "54 % et  83 %\n"
     ]
    }
   ],
   "source": [
    "#On crée une liste d'indices associés à 100 descriptions différentes de la base.\n",
    "rand_ind_list=[]\n",
    "for i in range(100):\n",
    "    num = random.randint(0, df1.shape[0])\n",
    "    while(num in rand_ind_list):\n",
    "        num = random.randint(0, df1.shape[0])\n",
    "    rand_ind_list.append(num)\n",
    "print(rand_ind_list)\n",
    "\n",
    "#On calcule le pourcentage de descriptions i telles que la description la plus proche de i dans la base soit i\n",
    "#On a constaté que souvent, lorsqu'une description ne matche pas avec elle-même, elle matche avec une description très\n",
    "#voisine qui est probablement proche de la description initiale en terme d'indice. En effet, on a souvent par exemple une\n",
    "#dizaine de photos illustrant le même évènement/fait d'actualité.\n",
    "#count2 doit remédier en partie à ce pb en étant incrémenté si la description la plus proche de i est i ou est\n",
    "#proche de i en terme d'indice (entre i-50 et i+50).\n",
    "count=0\n",
    "count2=0\n",
    "rand_int_list=range(100)\n",
    "for i in tqdm_notebook(rand_ind_list):\n",
    "    best=best_image3(nlp(df1.description[i]))\n",
    "    flag=0\n",
    "    if best==i:\n",
    "        count+=1\n",
    "        flag=1\n",
    "    for k in range(i-50,i+50):\n",
    "        if best==k:\n",
    "            count2+=1\n",
    "            flag=1\n",
    "            continue\n",
    "    if flag==0:\n",
    "        print(i,best) #si aucun compteur n'est incrémenté dans l'itération, potentielle erreur de l'algorithme.\n",
    "        #On print alors i et best pour voir par la suite si l'erreur était une vraie erreur ou pas.\n",
    "print(count,'% et ', count2,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colombian President Juan Manuel Santos (L) looks the FIFA World Cup trophy next to France's 1998 World Cup Champion, French-Argentine former footballer David Trezeguet, in Bogota, Colombia, on April 3, 2018 during the FIFA Trophy World Tour ahead of the World Cup to be held in Rusia between June 14 and July 15.   \n",
      " Colombian President Juan Manuel Santos (L) holds the FIFA World Cup trophy next to France's 1998 World Cup Champion, French-Argentine former footballer David Trezeguet, in Bogota, Colombia, on April 3, 2018 during the FIFA Trophy World Tour ahead of the World Cup to be held in Rusia between June 14 and July 15.  \n"
     ]
    }
   ],
   "source": [
    "print(df1.description[1625],'\\n',df1.description[1515])\n",
    "#On voit par exemple ici que malgré plus de 50 indices d'écarts, les descriptions sont quasiment identiques.\n",
    "#Le pourcentage de réussite de l'algorithme doit alors être encore revu à la hausse.\n",
    "#Après avoir étudié les descriptions associées aux indices ayant été print à la cellule précédente, on peut en fait\n",
    "#estimer que le vrai pourcentage de réussite de l'algorithme est supérieur à 90%.\n",
    "#Les seules erreurs constatées sont liées à  des descriptions identiques pour des dates différentes (on ne prend\n",
    "#actuellement pas en compte les dates dans les entités) ou bien des descriptions très proches avec seulement la 1ère phrase\n",
    "#qui diffère. Il faudrait alors accorder plus d'importance à la 1ère phrase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
